{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UF Research Computing  \n",
    "\n",
    "![UF Research Computing Logo](images/ufrc_logo.png)\n",
    "\n",
    "## Training module on Pytorch for image classification\n",
    "\n",
    "\n",
    "This training module is based off of the [Deep Learning with Pytorch: A 60 minute blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) tutorial by Soumith Chintala.\n",
    "\n",
    "It has been updated and customized fro running on HiPerGator by Matt Gitzendanner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: What is PyTorch?\n",
    "\n",
    "\n",
    "It’s a Python-based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "\n",
    "-  A replacement for NumPy to use the power of GPUs\n",
    "-  A deep learning research platform that provides maximum flexibility\n",
    "   and speed\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "\n",
    "### Tensors\n",
    "\n",
    "Tensors are similar to NumPy’s `ndarrays`, or more generally, a multidimensional matrix, with the additional benefit being that\n",
    "Tensors can also be used on a GPU to accelerate computing.\n",
    "\n",
    "Let's start by importing our needed modules: torch and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Do we need this?? #from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 5x3 matrix, uninitialized:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>An uninitialized matrix is declared,\n",
    "    but does not contain definite known\n",
    "    values before it is used. When an\n",
    "    uninitialized matrix is created,\n",
    "    whatever values were in the allocated\n",
    "    memory at the time will appear as the initial values.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0256e-08, 2.5783e-09, 3.0784e+12],\n",
      "        [6.9372e-07, 1.6902e-04, 2.6225e-09],\n",
      "        [1.2398e+16, 3.1369e+27, 1.6880e+25],\n",
      "        [2.5226e-18, 5.3693e-05, 5.4651e-05],\n",
      "        [2.1029e+20, 1.0488e-08, 1.9989e+20]])\n"
     ]
    }
   ],
   "source": [
    "# Uninitialized matrix\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized matrix:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5177, 0.2104, 0.9759],\n",
      "        [0.1042, 0.0430, 0.5432],\n",
      "        [0.0398, 0.4286, 0.5386],\n",
      "        [0.3898, 0.0866, 0.6811],\n",
      "        [0.9950, 0.1854, 0.1376]])\n"
     ]
    }
   ],
   "source": [
    "# Randomly initialized matrix\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a matrix filled zeros and of dtype long (a 64-bit integer):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix filled with 0s, specifying long integer data type\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor directly from data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# Matrix with specified values\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or create a tensor based on an existing tensor. These methods\n",
    "will reuse properties of the input tensor, e.g. dtype, and device (e.g. `device='cuda'`), unless\n",
    "new values are provided by user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-2.3073,  1.7252,  0.9808],\n",
      "        [ 0.4105,  0.2537, -0.2921],\n",
      "        [-0.3623, -0.0601,  0.2346],\n",
      "        [ 0.8938,  1.3957, -1.1560],\n",
      "        [ 0.9353,  0.4291, -0.0738]])\n"
     ]
    }
   ],
   "source": [
    "y = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(y)\n",
    "\n",
    "y = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(y)                                      # result has the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get its size:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
    "\n",
    "### Operations\n",
    "\n",
    "There are multiple syntaxes for operations. In the following\n",
    "example, we will take a look at the addition operation.\n",
    "\n",
    "Addition: syntax 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0721,  1.3995,  1.0863],\n",
      "        [-2.3711,  0.7235,  0.6999],\n",
      "        [-0.0660,  1.2769,  1.3639],\n",
      "        [ 1.0590, -0.0471, -0.5368],\n",
      "        [ 1.0610,  1.9492, -1.0509]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: syntax 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0721,  1.3995,  1.0863],\n",
      "        [-2.3711,  0.7235,  0.6999],\n",
      "        [-0.0660,  1.2769,  1.3639],\n",
      "        [ 1.0590, -0.0471, -0.5368],\n",
      "        [ 1.0610,  1.9492, -1.0509]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: providing an output tensor as argument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0721,  1.3995,  1.0863],\n",
      "        [-2.3711,  0.7235,  0.6999],\n",
      "        [-0.0660,  1.2769,  1.3639],\n",
      "        [ 1.0590, -0.0471, -0.5368],\n",
      "        [ 1.0610,  1.9492, -1.0509]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: in-place\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0721,  1.3995,  1.0863],\n",
      "        [-2.3711,  0.7235,  0.6999],\n",
      "        [-0.0660,  1.2769,  1.3639],\n",
      "        [ 1.0590, -0.0471, -0.5368],\n",
      "        [ 1.0610,  1.9492, -1.0509]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
    "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
    "\n",
    "You can use standard NumPy-like indexing with all bells and whistles!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is: \n",
      " tensor([[-0.0658,  0.5213,  0.7911],\n",
      "        [-2.4323,  0.6531,  0.6004],\n",
      "        [-1.0082,  0.9208,  0.4485],\n",
      "        [ 0.9685, -0.7695, -0.9071],\n",
      "        [ 0.7119,  1.9137, -1.4645]])\n",
      "Cloumn 1 of x is: tensor([ 0.5213,  0.6531,  0.9208, -0.7695,  1.9137])\n"
     ]
    }
   ],
   "source": [
    "print(\"x is: \\n\", x)\n",
    "print(\"Cloumn 1 of x is:\", x[:, 1]) # Rembember 0-indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([8, 2])\n",
      "tensor([[ 1.6179,  0.2050,  0.1634, -1.6854],\n",
      "        [ 0.3592, -0.9925,  1.1974, -0.5053],\n",
      "        [ 0.3456, -0.5126, -0.3245, -1.0524],\n",
      "        [ 0.8773, -0.9082, -0.2550, -1.0428]])\n",
      "tensor([ 1.6179,  0.2050,  0.1634, -1.6854,  0.3592, -0.9925,  1.1974, -0.5053,\n",
      "         0.3456, -0.5126, -0.3245, -1.0524,  0.8773, -0.9082, -0.2550, -1.0428])\n",
      "tensor([[ 1.6179,  0.2050],\n",
      "        [ 0.1634, -1.6854],\n",
      "        [ 0.3592, -0.9925],\n",
      "        [ 1.1974, -0.5053],\n",
      "        [ 0.3456, -0.5126],\n",
      "        [-0.3245, -1.0524],\n",
      "        [ 0.8773, -0.9082],\n",
      "        [-0.2550, -1.0428]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 2)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a one element tensor, use ``.item()`` to get the value as a\n",
    "Python number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5930])\n",
      "-1.5929841995239258\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read later\n",
    "\n",
    "\n",
    "  100+ Tensor operations, including transposing, indexing, slicing,\n",
    "  mathematical operations, linear algebra, random numbers, etc.,\n",
    "  are described here: [https://pytorch.org/docs/torch](https://pytorch.org/docs/torch)\n",
    "\n",
    "\n",
    "## NumPy Bridge\n",
    "\n",
    "\n",
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "\n",
    "The Torch Tensor and NumPy array will share their underlying memory\n",
    "locations (if the Torch Tensor is on CPU), and changing one will change\n",
    "the other.\n",
    "\n",
    "### Converting a Torch Tensor to a NumPy Array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the numpy array changed in value when the torch array is modified.\n",
    "\n",
    "This is similar to python lists. If `list1 = [1,2,3]` and you do `list2=list1`, you are telling python that `list2` should point to the same place in memory as `list1`. Changing an element in either list changes the corresponding element in the other--they are just different names pointing to the same memory structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 4., 4., 4., 4.])\n",
      "[4. 4. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting NumPy Array to Torch Tensor\n",
    "\n",
    "See how changing the np array changed the Torch Tensor automatically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Create a new np array\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to\n",
    "NumPy and back.\n",
    "\n",
    "CUDA Tensors\n",
    "------------\n",
    "\n",
    "Tensors can be moved onto any device using the ``.to`` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4642, 1.0532, 1.0966, 1.7360, 0.0656],\n",
      "        [1.0100, 1.1297, 1.0439, 0.7124, 1.6135],\n",
      "        [1.7370, 1.0953, 1.4682, 0.8548, 0.5511]], device='cuda:0')\n",
      "tensor([[0.4642, 1.0532, 1.0966, 1.7360, 0.0656],\n",
      "        [1.0100, 1.1297, 1.0439, 0.7124, 1.6135],\n",
      "        [1.7370, 1.0953, 1.4682, 0.8548, 0.5511]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# The if statement checks to see if a GPU is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.rand(3,5, device=device)     # directly create a tensor on GPU\n",
    "    x = torch.rand(3,5).to(device)         # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Continue to part 2 of the tutorial: 2_autograd_tutorial.ipynb](2_autograd_tutorial.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.1",
   "language": "python",
   "name": "tensorflow-2.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
